{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rnn import RNN\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import torchvision.transforms as transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - Batch loss: 5.289529480390101 - Time elapsed: 3.022756814956665\n",
      "Epoch 0 - Batch loss: 5.204101152868079 - Time elapsed: 2.6978771686553955\n",
      "Epoch 0 - Batch loss: 5.137353679477768 - Time elapsed: 2.7188100814819336\n",
      "Epoch 0 - Batch loss: 5.095253349150587 - Time elapsed: 2.6689984798431396\n",
      "Epoch 0 - Batch loss: 5.111417015126888 - Time elapsed: 2.696159839630127\n",
      "Epoch 0 - Batch loss: 5.118610970925965 - Time elapsed: 2.734889030456543\n",
      "Epoch 0 - Batch loss: 5.163402582975042 - Time elapsed: 2.659646511077881\n",
      "Epoch 0 - Batch loss: 5.056356340446728 - Time elapsed: 2.6453826427459717\n",
      "Epoch 0 - Batch loss: 5.113758061556208 - Time elapsed: 2.6634292602539062\n",
      "Epoch 0 - Batch loss: 5.143766057571309 - Time elapsed: 2.7251884937286377\n",
      "Epoch 0 - Batch loss: 5.158299388501468 - Time elapsed: 2.676537275314331\n",
      "Epoch 0 - Batch loss: 5.160338945836829 - Time elapsed: 2.6463465690612793\n",
      "Epoch 0 - Batch loss: 5.104068218461619 - Time elapsed: 2.6983137130737305\n",
      "Epoch 0 - Batch loss: 5.185538272729656 - Time elapsed: 2.6477768421173096\n",
      "Epoch 0 - Batch loss: 5.10413334993708 - Time elapsed: 2.6603622436523438\n",
      "Epoch 0 - Batch loss: 5.154596725566275 - Time elapsed: 2.743225336074829\n",
      "Epoch 0 - Batch loss: 5.169524532036493 - Time elapsed: 2.6398370265960693\n",
      "Epoch 0 - Batch loss: 5.121484538852768 - Time elapsed: 2.6574957370758057\n",
      "Epoch 0 - Batch loss: 5.1912792641044465 - Time elapsed: 2.6776139736175537\n",
      "Epoch 0 - Batch loss: 5.178648263816066 - Time elapsed: 2.7398548126220703\n",
      "Epoch 0 - Batch loss: 5.189557990771812 - Time elapsed: 2.674562454223633\n",
      "Epoch 0 - Batch loss: 5.11510493131292 - Time elapsed: 2.7719061374664307\n",
      "Epoch 0 - Batch loss: 5.135010175256921 - Time elapsed: 2.7502312660217285\n",
      "Epoch 0 - Batch loss: 5.099347620202391 - Time elapsed: 2.652899742126465\n",
      "Epoch 0 - Batch loss: 5.1029216587143456 - Time elapsed: 2.7000043392181396\n",
      "Epoch 0 - Batch loss: 5.099730216416736 - Time elapsed: 2.6694517135620117\n",
      "Epoch 0 - Batch loss: 5.187451663433305 - Time elapsed: 2.73445463180542\n",
      "Epoch 0 - Training loss: 138.89058444643982\n",
      "Epoch 1 - Batch loss: 5.066236252752726 - Time elapsed: 2.677786350250244\n",
      "Epoch 1 - Batch loss: 5.17654234610948 - Time elapsed: 2.7070837020874023\n",
      "Epoch 1 - Batch loss: 5.13532927852349 - Time elapsed: 2.795332431793213\n",
      "Epoch 1 - Batch loss: 5.08831049771917 - Time elapsed: 2.6883182525634766\n",
      "Epoch 1 - Batch loss: 5.138964761823615 - Time elapsed: 2.695225954055786\n",
      "Epoch 1 - Batch loss: 5.116573461750209 - Time elapsed: 2.743682622909546\n",
      "Epoch 1 - Batch loss: 5.135902353581166 - Time elapsed: 2.651252269744873\n",
      "Epoch 1 - Batch loss: 5.114975077993917 - Time elapsed: 2.6903891563415527\n",
      "Epoch 1 - Batch loss: 5.125376451735528 - Time elapsed: 2.6717464923858643\n",
      "Epoch 1 - Batch loss: 5.149684419567953 - Time elapsed: 2.7730600833892822\n",
      "Epoch 1 - Batch loss: 5.156254096319212 - Time elapsed: 2.628544807434082\n",
      "Epoch 1 - Batch loss: 5.196257111210151 - Time elapsed: 2.613067388534546\n",
      "Epoch 1 - Batch loss: 5.142857903602139 - Time elapsed: 2.7601981163024902\n",
      "Epoch 1 - Batch loss: 5.131947767014472 - Time elapsed: 2.644294261932373\n",
      "Epoch 1 - Batch loss: 5.145792916317114 - Time elapsed: 2.6950714588165283\n",
      "Epoch 1 - Batch loss: 5.151407741060193 - Time elapsed: 2.6417577266693115\n",
      "Epoch 1 - Batch loss: 5.110829602951972 - Time elapsed: 2.7441020011901855\n",
      "Epoch 1 - Batch loss: 5.1702262315174075 - Time elapsed: 2.628530263900757\n",
      "Epoch 1 - Batch loss: 5.11383056640625 - Time elapsed: 2.6864004135131836\n",
      "Epoch 1 - Batch loss: 5.168760568503566 - Time elapsed: 2.781611204147339\n",
      "Epoch 1 - Batch loss: 5.057241555028313 - Time elapsed: 2.680748462677002\n",
      "Epoch 1 - Batch loss: 5.094817910418414 - Time elapsed: 2.6504979133605957\n",
      "Epoch 1 - Batch loss: 5.182539357434983 - Time elapsed: 2.6792218685150146\n",
      "Epoch 1 - Batch loss: 5.096987321072777 - Time elapsed: 2.74459171295166\n",
      "Epoch 1 - Batch loss: 5.094370592360528 - Time elapsed: 2.685389757156372\n",
      "Epoch 1 - Batch loss: 5.167803258703859 - Time elapsed: 2.6813504695892334\n",
      "Epoch 1 - Batch loss: 5.178074369494547 - Time elapsed: 2.724203109741211\n",
      "Epoch 1 - Training loss: 138.60789377097316\n",
      "Epoch 2 - Batch loss: 5.108280053874791 - Time elapsed: 2.6553657054901123\n",
      "Epoch 2 - Batch loss: 5.143238042024958 - Time elapsed: 2.68243408203125\n",
      "Epoch 2 - Batch loss: 5.158550492869128 - Time elapsed: 2.7031633853912354\n",
      "Epoch 2 - Batch loss: 5.1718217478502515 - Time elapsed: 2.6292238235473633\n",
      "Epoch 2 - Batch loss: 5.115296639052014 - Time elapsed: 2.6573874950408936\n",
      "Epoch 2 - Batch loss: 5.172014684485109 - Time elapsed: 2.6591362953186035\n",
      "Epoch 2 - Batch loss: 5.1156169712143456 - Time elapsed: 2.7463366985321045\n",
      "Epoch 2 - Batch loss: 5.232110145108011 - Time elapsed: 2.6463699340820312\n",
      "Epoch 2 - Batch loss: 5.120592360528524 - Time elapsed: 2.6637470722198486\n",
      "Epoch 2 - Batch loss: 5.113702351614933 - Time elapsed: 2.7571256160736084\n",
      "Epoch 2 - Batch loss: 5.138009090551594 - Time elapsed: 2.6740221977233887\n",
      "Epoch 2 - Batch loss: 5.073764468199455 - Time elapsed: 2.687673568725586\n",
      "Epoch 2 - Batch loss: 5.192366017591233 - Time elapsed: 2.7029869556427\n",
      "Epoch 2 - Batch loss: 5.083207712877517 - Time elapsed: 2.761418104171753\n",
      "Epoch 2 - Batch loss: 5.161931594746225 - Time elapsed: 2.672640562057495\n",
      "Epoch 2 - Batch loss: 5.171822157482173 - Time elapsed: 2.6557412147521973\n",
      "Epoch 2 - Batch loss: 5.18343235502307 - Time elapsed: 2.7427473068237305\n",
      "Epoch 2 - Batch loss: 5.0586470021497485 - Time elapsed: 2.659395694732666\n",
      "Epoch 2 - Batch loss: 5.127354564282718 - Time elapsed: 2.701921224594116\n",
      "Epoch 2 - Batch loss: 5.102792215027265 - Time elapsed: 2.7583389282226562\n",
      "Epoch 2 - Batch loss: 5.15689271248427 - Time elapsed: 2.645740509033203\n",
      "Epoch 2 - Batch loss: 5.142282370752937 - Time elapsed: 2.7396481037139893\n",
      "Epoch 2 - Batch loss: 5.083527225776007 - Time elapsed: 2.6535003185272217\n",
      "Epoch 2 - Batch loss: 5.1239730527736995 - Time elapsed: 2.767256259918213\n",
      "Epoch 2 - Batch loss: 5.103047006082215 - Time elapsed: 2.6496589183807373\n",
      "Epoch 2 - Batch loss: 5.132585973547609 - Time elapsed: 2.682412624359131\n",
      "Epoch 2 - Batch loss: 5.123399977716024 - Time elapsed: 2.8196630477905273\n",
      "Epoch 2 - Training loss: 138.61025898568582\n",
      "Epoch 3 - Batch loss: 5.131629073379824 - Time elapsed: 2.6670916080474854\n",
      "Epoch 3 - Batch loss: 5.12033634057781 - Time elapsed: 2.646958351135254\n",
      "Epoch 3 - Batch loss: 5.119634641096896 - Time elapsed: 2.662565231323242\n",
      "Epoch 3 - Batch loss: 5.137816973180579 - Time elapsed: 2.71531081199646\n",
      "Epoch 3 - Batch loss: 5.155232474307886 - Time elapsed: 2.7236948013305664\n",
      "Epoch 3 - Batch loss: 5.140879381423028 - Time elapsed: 2.6363601684570312\n",
      "Epoch 3 - Batch loss: 5.089393564518666 - Time elapsed: 2.759007215499878\n",
      "Epoch 3 - Batch loss: 5.109492564361368 - Time elapsed: 2.6727771759033203\n",
      "Epoch 3 - Batch loss: 5.166399040478188 - Time elapsed: 2.6850674152374268\n",
      "Epoch 3 - Batch loss: 5.120465784264891 - Time elapsed: 2.763697385787964\n",
      "Epoch 3 - Batch loss: 5.074147474045722 - Time elapsed: 2.660804271697998\n",
      "Epoch 3 - Batch loss: 5.059857874108641 - Time elapsed: 2.6507740020751953\n",
      "Epoch 3 - Batch loss: 5.165823507628985 - Time elapsed: 2.683621644973755\n",
      "Epoch 3 - Batch loss: 5.174371706559354 - Time elapsed: 2.720738172531128\n",
      "Epoch 3 - Batch loss: 5.137943139812291 - Time elapsed: 2.6811554431915283\n",
      "Epoch 3 - Batch loss: 5.134182718776216 - Time elapsed: 2.6643433570861816\n",
      "Epoch 3 - Batch loss: 5.114275426672609 - Time elapsed: 2.7610034942626953\n",
      "Epoch 3 - Batch loss: 5.104260335832635 - Time elapsed: 2.648610830307007\n",
      "Epoch 3 - Batch loss: 5.161676394059354 - Time elapsed: 2.687974452972412\n",
      "Epoch 3 - Batch loss: 5.146685504273281 - Time elapsed: 2.660531520843506\n",
      "Epoch 3 - Batch loss: 5.167100330327181 - Time elapsed: 2.783590316772461\n",
      "Epoch 3 - Batch loss: 5.167226087326972 - Time elapsed: 2.680203676223755\n",
      "Epoch 3 - Batch loss: 5.067704783190017 - Time elapsed: 2.682640552520752\n",
      "Epoch 3 - Batch loss: 5.175011961252097 - Time elapsed: 2.7766647338867188\n",
      "Epoch 3 - Batch loss: 5.110959046639052 - Time elapsed: 2.6507885456085205\n",
      "Epoch 3 - Batch loss: 5.177117469326761 - Time elapsed: 2.655867099761963\n",
      "Epoch 3 - Batch loss: 5.177563148856963 - Time elapsed: 2.7377965450286865\n",
      "Epoch 3 - Training loss: 138.60718674627728\n",
      "Epoch 4 - Batch loss: 5.15804173002307 - Time elapsed: 2.6726577281951904\n",
      "Epoch 4 - Batch loss: 5.102728312447567 - Time elapsed: 2.662858486175537\n",
      "Epoch 4 - Batch loss: 5.165121398516149 - Time elapsed: 2.663968563079834\n",
      "Epoch 4 - Batch loss: 5.142984070233851 - Time elapsed: 2.741548538208008\n",
      "Epoch 4 - Batch loss: 5.1082161512950925 - Time elapsed: 2.670140027999878\n",
      "Epoch 4 - Batch loss: 5.177371850749791 - Time elapsed: 2.695901870727539\n",
      "Epoch 4 - Batch loss: 5.115551430106963 - Time elapsed: 2.770236015319824\n",
      "Epoch 4 - Batch loss: 5.181838477217911 - Time elapsed: 2.641131639480591\n",
      "Epoch 4 - Batch loss: 5.144833967989723 - Time elapsed: 2.673170566558838\n",
      "Epoch 4 - Batch loss: 5.077911991401007 - Time elapsed: 2.7075254917144775\n",
      "Epoch 4 - Batch loss: 5.126973196964136 - Time elapsed: 2.7558951377868652\n",
      "Epoch 4 - Batch loss: 5.177627461068583 - Time elapsed: 2.6366560459136963\n",
      "Epoch 4 - Batch loss: 5.099728577889052 - Time elapsed: 2.6372787952423096\n",
      "Epoch 4 - Batch loss: 5.100687526216443 - Time elapsed: 2.7151689529418945\n",
      "Epoch 4 - Batch loss: 5.144389107723364 - Time elapsed: 2.6521592140197754\n",
      "Epoch 4 - Batch loss: 5.120654624580537 - Time elapsed: 2.695619821548462\n",
      "Epoch 4 - Batch loss: 5.115169243524538 - Time elapsed: 2.6650550365448\n",
      "Epoch 4 - Batch loss: 5.146365581742869 - Time elapsed: 2.7429301738739014\n",
      "Epoch 4 - Batch loss: 5.088820079829069 - Time elapsed: 2.6705291271209717\n",
      "Epoch 4 - Batch loss: 5.155806778261326 - Time elapsed: 2.7168524265289307\n",
      "Epoch 4 - Batch loss: 5.105089840472945 - Time elapsed: 2.7260489463806152\n",
      "Epoch 4 - Batch loss: 5.13858216560927 - Time elapsed: 2.6371042728424072\n",
      "Epoch 4 - Batch loss: 5.11599915779677 - Time elapsed: 2.63031005859375\n",
      "Epoch 4 - Batch loss: 5.1531933266044465 - Time elapsed: 2.7687690258026123\n",
      "Epoch 4 - Batch loss: 5.162315419856334 - Time elapsed: 2.652374505996704\n",
      "Epoch 4 - Batch loss: 5.144836016149329 - Time elapsed: 2.7145731449127197\n",
      "Epoch 4 - Batch loss: 5.143047972813549 - Time elapsed: 2.6576764583587646\n",
      "Epoch 4 - Training loss: 138.61388545708368\n",
      "Finished training\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import train_rnn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu = torch.device(\"cpu\")\n",
    "\n",
    "# free up the gpu memory\n",
    "train_rnn.model = train_rnn.model.to(cpu)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rnn.model\n",
    "torch.save(train_rnn.model.state_dict(), \"rnn_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tokenizer\n",
    "model = RNN(tokenizer.ALPHABET_SIZE, 100, tokenizer.ALPHABET_SIZE, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "import sspear_parse\n",
    "import torch.nn as nn\n",
    "criterion = nn.CrossEntropyLoss() \n",
    "\n",
    "\n",
    "epochs = 3\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    h_i = model.h_0\n",
    "    for i in range(len(sspear_parse.nextwords500) - 1):\n",
    "        x_i = sspear_parse.nextwords500[i]\n",
    "        y_i = sspear_parse.nextwords500[i+1]\n",
    "\n",
    "        #clear gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        y_pred, h_i = model(x_i, h_i) \n",
    "        print(y_pred)\n",
    "        #calculate loss\n",
    "        loss = criterion(y_pred, y_i)\n",
    "\n",
    "        #backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        #update parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    print(\"Epoch {} - Training loss: {}\".format(epoch, running_loss/len(trainloader)))\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print pred\n",
    "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
    "images = images.view(images.shape[0], -1)\n",
    "pred = model(images)\n",
    "ap = torch.argmax(pred, dim=1)\n",
    "print(pred)\n",
    "print(ap)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
